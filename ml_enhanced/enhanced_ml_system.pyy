import numpy as np
import pandas as pd
import xgboost as xgb
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
import logging
from typing import Dict, Tuple, List, Any
import joblib
from datetime import datetime
import os

class EnhancedMLSystem:
    def __init__(self, save_path: str = 'models/', log_path: str = 'logs/'):
        """
        Initialize the enhanced ML system that combines XGBoost and RandomForest for short-term predictions.

        Args:
            save_path: Directory to save trained models.
            log_path: Directory to save logs.
        """
        self.models = {
            'xgboost': None,
            'random_forest': None
        }
        self.weights = {
            'xgboost': 0.5,
            'random_forest': 0.5
        }
        self.save_path = save_path
        self.log_path = log_path

        # Ensure directories exist
        os.makedirs(self.save_path, exist_ok=True)
        os.makedirs(self.log_path, exist_ok=True)

        self.performance_history = {
            'xgboost': [],
            'random_forest': []
        }

        # Set up logging
        log_filename = os.path.join(self.log_path, f"ml_system_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log")
        logging.basicConfig(filename=log_filename, level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
        logging.info("EnhancedMLSystem initialized.")

    def initialize_models(self, xgb_params: Dict[str, Any] = None, rf_params: Dict[str, Any] = None):
        """
        Initialize the XGBoost and RandomForest models with given parameters or defaults.
        """
        if xgb_params is None:
            xgb_params = {
                'n_estimators': 100,
                'max_depth': 3,
                'learning_rate': 0.1,
                'use_label_encoder': False
            }
        if rf_params is None:
            rf_params = {
                'n_estimators': 100,
                'max_depth': 5,
                'random_state': 42
            }

        self.models['xgboost'] = xgb.XGBClassifier(**xgb_params)
        self.models['random_forest'] = RandomForestClassifier(**rf_params)
        logging.info("Models initialized with given parameters.")

    def train_models(self, X: pd.DataFrame, y: np.ndarray, test_size: float = 0.2, random_state: int = 42):
        """
        Train both XGBoost and RandomForest models and evaluate their performance.
        
        Args:
            X: Feature matrix as a Pandas DataFrame.
            y: Target array.
            test_size: Fraction of data to use as test set.
            random_state: Random state for reproducibility.
        """
        logging.info("Starting model training.")

        # Split the data
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)
        
        # Convert columns to a simple RangeIndex to avoid Int64Index errors with XGBoost
        X_train.columns = range(X_train.shape[1])
        X_test.columns = range(X_test.shape[1])

        # Train XGBoost
        self.models['xgboost'].fit(X_train, y_train)
        y_pred_xgb = self.models['xgboost'].predict(X_test)

        # Train RandomForest
        self.models['random_forest'].fit(X_train, y_train)
        y_pred_rf = self.models['random_forest'].predict(X_test)

        # Evaluate performance
        acc_xgb = accuracy_score(y_test, y_pred_xgb)
        prec_xgb = precision_score(y_test, y_pred_xgb, average='macro', zero_division=0)
        rec_xgb = recall_score(y_test, y_pred_xgb, average='macro', zero_division=0)
        f1_xgb = f1_score(y_test, y_pred_xgb, average='macro', zero_division=0)

        acc_rf = accuracy_score(y_test, y_pred_rf)
        prec_rf = precision_score(y_test, y_pred_rf, average='macro', zero_division=0)
        rec_rf = recall_score(y_test, y_pred_rf, average='macro', zero_division=0)
        f1_rf = f1_score(y_test, y_pred_rf, average='macro', zero_division=0)

        # Log performance
        logging.info(f"XGBoost Performance: Accuracy={acc_xgb}, Precision={prec_xgb}, Recall={rec_xgb}, F1={f1_xgb}")
        logging.info(f"RandomForest Performance: Accuracy={acc_rf}, Precision={prec_rf}, Recall={rec_rf}, F1={f1_rf}")

        self.performance_history['xgboost'].append((acc_xgb, prec_xgb, rec_xgb, f1_xgb))
        self.performance_history['random_forest'].append((acc_rf, prec_rf, rec_rf, f1_rf))

        # Save models
        self.save_models()

    def predict(self, X: pd.DataFrame) -> np.ndarray:
        """
        Predict the final output by averaging predictions from XGBoost and RandomForest
        weighted by their assigned weights.
        
        Args:
            X: Feature matrix for prediction.
        Returns:
            Final predictions as a numpy array.
        """
        if self.models['xgboost'] is None or self.models['random_forest'] is None:
            raise ValueError("Models are not trained. Call `train_models` first.")

        # Convert columns to RangeIndex if needed
        X.columns = range(X.shape[1])

        preds_xgb = self.models['xgboost'].predict_proba(X)[:, 1]
        preds_rf = self.models['random_forest'].predict_proba(X)[:, 1]

        final_preds = (self.weights['xgboost'] * preds_xgb) + (self.weights['random_forest'] * preds_rf)
        return (final_preds >= 0.5).astype(int)

    def save_models(self):
        """
        Save both models to the save_path directory.
        """
        xgb_path = os.path.join(self.save_path, "xgboost_model.joblib")
        rf_path = os.path.join(self.save_path, "random_forest_model.joblib")

        joblib.dump(self.models['xgboost'], xgb_path)
        joblib.dump(self.models['random_forest'], rf_path)

        logging.info("Models saved successfully.")

    def load_models(self):
        """
        Load models from the save_path directory, if they exist.
        """
        xgb_path = os.path.join(self.save_path, "xgboost_model.joblib")
        rf_path = os.path.join(self.save_path, "random_forest_model.joblib")

        if os.path.exists(xgb_path):
            self.models['xgboost'] = joblib.load(xgb_path)
        else:
            logging.warning("XGBoost model file not found.")

        if os.path.exists(rf_path):
            self.models['random_forest'] = joblib.load(rf_path)
        else:
            logging.warning("RandomForest model file not found.")

    def update_weights(self, xgb_weight: float, rf_weight: float):
        """
        Update the weights used in the final prediction.
        
        Args:
            xgb_weight: Weight for XGBoost model predictions.
            rf_weight: Weight for RandomForest model predictions.
        """
        if xgb_weight < 0 or xgb_weight > 1 or rf_weight < 0 or rf_weight > 1:
            raise ValueError("Weights must be between 0 and 1.")
        if xgb_weight + rf_weight != 1.0:
            raise ValueError("Weights must sum to 1.")
        
        self.weights['xgboost'] = xgb_weight
        self.weights['random_forest'] = rf_weight
        logging.info(f"Updated weights: XGBoost={xgb_weight}, RandomForest={rf_weight}")
